import pathlib
import os
import re

configfile: "config/config.yaml"

OUTPUT_DIR = pathlib.Path(config["output_dir"])
INPUT_MFASTA = pathlib.Path(config["input"])
FILTER_EXPRESSION = config["filter_expression"]

AF_THRESHOLD = config["AF_THRESHOLD"]

if 0 <= AF_THRESHOLD <= 1:
    pass
else:
    raise ValueError("0<=AF_THRESHOLD<=1")

def aggregate_input(wildcards):
    """
    aggregate the file names of the random number of files
    generated at the scatter step
    """
    checkpoint_output = checkpoints.mfasta_split.get(**wildcards).output[0]
    return expand(OUTPUT_DIR/"tmp/vcf_filt/{sequences}.filt.vcf.gz",
           sequences=glob_wildcards(os.path.join(checkpoint_output, "{sequences}.fasta")).sequences)

def find_ref(wildcards):
    """
    Within the output of mfasta_split it finds a file name with the "REF_" prefix that was added by the script
    Will match the pattern "/REF_<anysequence>.fasta"
    """
    checkpoint_output = checkpoints.mfasta_split.get().output[0]
    all_files = expand(OUTPUT_DIR/"individual_seqs/{sequences}.fasta", sequences=glob_wildcards(os.path.join(checkpoint_output, "{sequences}.fasta")).sequences)
    ref = [x for x in all_files if re.search("/REF_.*\.fasta$", x)][0]
    return ref

rule all:
    input:
         OUTPUT_DIR/"masked.fasta"

# Need to add logs/message/conda env
checkpoint mfasta_split:
    input:
        INPUT_MFASTA
    output:
        directory(OUTPUT_DIR/"individual_seqs")
    params:
        OUTPUT_DIR/"individual_seqs"
    script:
        "scripts/split_multifa.py"

rule generate_vcf:
    input:
        referance_dir = find_ref,
        query_dir = OUTPUT_DIR/"individual_seqs/{sequences}.fasta"
    output:
        OUTPUT_DIR/"vcf/{sequences}.vcf"
    shell:
        "python ncov-random-scripts/quick_align.py -g {input.query_dir} -r {input.referance_dir} -o vcf > {output}"

rule compress_vcf:
    input:
        OUTPUT_DIR/"vcf/{sequences}.vcf"
    output:
        OUTPUT_DIR/"tmp/vcf_gz/{sequences}.vcf.gz"
    shell:
        "bgzip -c {input} > {output}; tabix -p vcf {output}"

rule filter_vcf:
    input:
        OUTPUT_DIR/"tmp/vcf_gz/{sequences}.vcf.gz"
    params:
        FILTER_EXPRESSION
    output:
        OUTPUT_DIR/"tmp/vcf_filt/{sequences}.filt.vcf.gz"
    shell:
        "bcftools filter -e '{params}' {input} -O z > {output}; tabix -p vcf {output}"
    
rule merge_vcf:
    input:
        aggregate_input
    output:
        OUTPUT_DIR/"tmp/merged.vcf"
    shell:
        "bcftools merge -0 {input} --force-samples > {output}"

rule calc_tags:
    input:
        OUTPUT_DIR/"tmp/merged.vcf"
    output:
        OUTPUT_DIR/"tmp/merged.tags.vcf"
    shell:
        "bcftools +fill-tags {input} -- -t AF,NS > {output}"

rule threshold_check:
    input:
        OUTPUT_DIR/"tmp/merged.tags.vcf"
    params:
        AF_THRESHOLD
    output:
        OUTPUT_DIR/"tmp/merged.tags.pass.vcf"
    shell:
        "bcftools filter -i 'INFO/AF[0] > {params}' {input} > {output}"

rule sort_vcf:
    input:
        OUTPUT_DIR/"tmp/merged.tags.pass.vcf"
    output:
        OUTPUT_DIR/"tmp/sorted.vcf"
    shell:
        "bcftools sort {input} > {output}"

rule normalise_vcf:
    input:
        OUTPUT_DIR/"tmp/sorted.vcf"
    output:
        OUTPUT_DIR/"tmp/norm.vcf"
    shell:
        "bcftools norm -m +any {input} > {output}"

rule mask_ref:
    input:
        referance_dir = find_ref,
        norm_vcf =  OUTPUT_DIR/"tmp/norm.vcf"
    output:
         OUTPUT_DIR/"masked.fasta"
    shell:
        "bedtools maskfasta -fi {input.referance_dir} -bed {input.norm_vcf} -fo {output}"







